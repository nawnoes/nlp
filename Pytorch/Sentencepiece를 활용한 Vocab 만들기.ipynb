{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Senctencepice를 활용한 Vocab 만들기\n",
    "구글 SentencePice를 활용해 Vocab 만들기. 많은 말뭉치를 사용하는 경우 Vocab을 만드는 것은 어려운 방법\n",
    "\n",
    "1. character level  \n",
    "캐릭터 단위로 voacal을 만드는것. 한국어 기준으로, 자음 모음 단어를 기준. 각 단어의 고유한 의미를 표현하지는 않기 때문에 좋은 성능을 내지 못하는 경우가 많다.  \n",
    "  \n",
    "2. space level  \n",
    "띄어쓰기 단위로 vocab. 한국어 경우 조사/ 어미 등으로 인한 중복 단어 문제 발생.\n",
    "\n",
    "3. subword level  \n",
    "많은 단어를 처리 가능하고, unknown이 발생할 확률을 줄이는 방법. **단어의 빈도수**를 계산해서 subword 단위로 쪼개는 방법. 단어를 쉽게 쪼갤 수 있도록 google에서 **sentencepiece** 툴 제공. 아래에서는 BPE(Byte Pair Encoding) 사용.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 말뭉치 만들기(한국어 위키)\n",
    "vocab을 이용한 말뭉치 필요. 한국어 위키 말뭉치를 사용 예정 [위키백과: 데이터 베이스 다운로드](https://dumps.wikimedia.org/kowiki/20200101/) 에서 1월 1일 자의 page-articles.xml.bz2 파일을 다운로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "web-crawler를 다운 받아서 말뭉치를 만드것까지 한번에 처리\n",
    "```js\n",
    "$ git clone https://github.com/paul-hyun/web-crawler.git\n",
    "$ cd web-crawler\n",
    "$ pip install tqdm\n",
    "$ pip install pandas\n",
    "$ pip install bs4\n",
    "$ pip install wget\n",
    "$ pip install pymongo\n",
    "$ python kowiki.py\n",
    "```\n",
    "위 절차를 완료 하면 kowiki 폴더 아래 kowiki_[날짜].csv 형태의 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "in_file = \"/Users/a60058238/Desktop/dev/workspace/nlp-study/Pytorch/kowiki/web-crawler/kowiki/kowiki_20200107.csv\"\n",
    "out_file = \"/Users/a60058238/Desktop/dev/workspace/nlp-study/Pytorch/kowiki/kowiki.txt\"\n",
    "\n",
    "SEPARATOR = u\"\\u241D\"\n",
    "\n",
    "df = pd.read_csv(in_file, sep=SEPARATOR, engine =\"python\")\n",
    "\n",
    "with open(out_file,\"w\") as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(row[\"text\"]) # 타이틀과 텍스트는 중복되므로 텍스트만 저장\n",
    "        f.write(\"\\n\\n\\n\\n\") # 구분자 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위키데이터의 경우 본문(text)에 제목(title) 정보를 포함하고 있어서 제목과 본문을 둘다 저장할 경우, 내용이 중복된다. 그리고 위키 문서별로 구분하기 위해 줄바꿈을 **4**개로 주었다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 아나콘다 설치 시 오류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ee811717caa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mPytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentencepiece\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetencePieceTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Pytorch'"
     ]
    }
   ],
   "source": [
    "import Pytorch.sentencepiece as spm\n",
    "\n",
    "spm.SetencePieceTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Google Sentencepiece 설치\n",
    "Anaconda & Mac 환경에서 setencepiece를 설치하는데 어려움.\n",
    "```\n",
    "conda install -c roccqqck sentencepiece\n",
    "``` \n",
    "으로 sentencepiece 패키지 설치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sentencepiece' has no attribute 'SentencePieceTrainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b97fad70b9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m spm.SentencePieceTrainer.train(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;34mf\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m\" --model_type=bpe\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sentencepiece' has no attribute 'SentencePieceTrainer'"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "corpus = \"kowiki.txt\"\n",
    "prefix = \"kowiki\"\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" + \n",
    "    \" --model_type=bpe\" +\n",
    "    \" --max_sentence_length=999999\" + # 문장 최대 길이\n",
    "    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n",
    "    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n",
    "    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n",
    "    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n",
    "    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SentencePieceTrainer.train** 옵션\n",
    "- input: 입력 corpus\n",
    "- prefix: 저장할 모델 이름\n",
    "- vocab_size: vocab 개수 (기본 8,000에 스페셜 토큰 7개를 더해서 8,007개)\n",
    "- max_sentence_length: 문장의 최대 길이\n",
    "- pad_id, pad_piece: pad token id, 값\n",
    "- unk_id, unk_piece: unknown token id, 값\n",
    "- bos_id, bos_piece: begin of sentence token id, 값\n",
    "- eos_id, eos_piece: end of sequence token id, 값\n",
    "- user_defined_symbols: 사용자 정의 토큰\n",
    "\n",
    "> vocab_size의 경우 Etri KoBERT의 경우 32,000개 sktKoBERT의 경우 8,000개 사용.\n",
    "> vocab_size가 커지면 성능이 좋아지고, 모델 파라미터 수는 증가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab 생성이 완료되면, kowiki.model과 kowiki.vocab 파일이 생성된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vocab 테스트\n",
    "생성된 vocab을 이용한 간단한 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/a60058238/Desktop/dev/workspace/nlp-study/Pytorch',\n",
       " '/Users/a60058238/opt/anaconda3/lib/python37.zip',\n",
       " '/Users/a60058238/opt/anaconda3/lib/python3.7',\n",
       " '/Users/a60058238/opt/anaconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/a60058238/.local/lib/python3.7/site-packages',\n",
       " '/Users/a60058238/opt/anaconda3/lib/python3.7/site-packages',\n",
       " '/Users/a60058238/opt/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/a60058238/opt/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/a60058238/.ipython']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sentencepiece' has no attribute 'SentencePieceProcessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a5f6467f54ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<path of vocab>/kowiki.model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m lines = [\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sentencepiece' has no attribute 'SentencePieceProcessor'"
     ]
    }
   ],
   "source": [
    "vocab_file = \"<path of vocab>/kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "\n",
    "lines = [\n",
    "  \"겨울이 되어서 날씨가 무척 추워요.\",\n",
    "  \"이번 성탄절은 화이트 크리스마스가 될까요?\",\n",
    "  \"겨울에 감기 조심하시고 행복한 연말 되세요.\"\n",
    "]\n",
    "for line in lines:\n",
    "  pieces = vocab.encode_as_pieces(line)\n",
    "  ids = vocab.encode_as_ids(line)\n",
    "  print(line)\n",
    "  print(pieces)\n",
    "  print(ids)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 프로그램의 subword 단위로 쪼개는 것을 확인할 수 있다.\n",
    "\n",
    "쪼개진 결과는 아래와 같다\n",
    "```\n",
    "겨울이 되어서 날씨가 무척 추워요.\n",
    "['▁겨울', '이', '▁되어', '서', '▁날', '씨', '가', '▁무', '척', '▁추', '워', '요', '.']\n",
    "[3091, 3588, 601, 3602, 683, 4014, 3599, 108, 4193, 206, 3958, 3760, 3590]\n",
    "\n",
    "이번 성탄절은 화이트 크리스마스가 될까요?\n",
    "['▁이번', '▁성', '탄', '절', '은', '▁화', '이트', '▁크리스', '마', '스가', '▁될', '까', '요', '?']\n",
    "[3224, 86, 3967, 3923, 3604, 264, 669, 1970, 3664, 780, 1450, 3794, 3760, 4245]\n",
    "\n",
    "겨울에 감기 조심하시고 행복한 연말 되세요.\n",
    "['▁겨울', '에', '▁감', '기', '▁조', '심', '하', '시', '고', '▁행', '복', '한', '▁연', '말', '▁되', '세', '요', '.']\n",
    "[3091, 3591, 212, 3605, 53, 3832, 3596, 3613, 3600, 234, 3871, 3603, 61, 3823, 445, 3682, 3760, 3590]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://paul-hyun.github.io/vocab-with-sentencepiece/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
